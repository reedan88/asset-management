{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTDMO Metadata Review\n",
    "\n",
    "This notebook describes the process for reviewing the calibration coefficients for the CTDMO IM-37. The purpose is to check the calibration coefficients contained in the CSVs stored within the asset management repository on GitHub, which are the coefficients utilized by OOI-net for calculating data products, against the different available sources of calibration information to identify when errors were made during entering the calibration csvs. This includes checking the following information:\n",
    "1. The calibration date - this information is stored in the filename of the csv\n",
    "2. Calibration source - identifying all the possible sources of calibration information, and determine which file should supply the calibration info\n",
    "3. Calibration coeffs - checking the accuracy and precision of the numbers stored in the calibration coefficients\n",
    "\n",
    "The CTDMO contains 24 different calibration coefficients to check. The possible calibration sources for the CTDMOs are vendor PDFs, vendor .cal files, and QCT check-ins. A complication is that the vendor documents are principally available only as PDFs that are copies of images. This requires the use of Optical Character Recognition (OCR) in order to parse the PDFs. Unfortunately, OCR frequently misinterprets certain character combinations, since it utilizes Levenstein-distance to do character matching. \n",
    "\n",
    "Furthermore, using OCR to read PDFs requires significant preprocessing of the PDFs to create individual PDFs with uniform metadata and encoding. Without this preprocessing, the OCR will not generate uniformly spaced characters, making parsing not amenable to repeatable automated parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import likely important packages, etc.\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "Define the directories where the QCT document files are stored as well as where the vendor documents are stored, where asset tracking is located, and where the calibration csvs are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/CTDMO/CTDMO_Results'\n",
    "cal_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/CTDMO/CTDMO_Cal'\n",
    "asset_management_directory = '/home/andrew/Documents/OOI-CGSN/ooi-integration/asset-management/calibration/CTDMOG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_spreadsheet = '/media/andrew/OS/Users/areed/Documents/Project_Files/Documentation/System/System Notebook/WHOI_Asset_Tracking.xlsx'\n",
    "sheet_name = 'Sensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDMO = whoi_asset_tracking(excel_spreadsheet,sheet_name,instrument_class='CTDMO',whoi=True,series='G')\n",
    "CTDMO.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**======================================================================================================================**\n",
    "\n",
    "First, get all the unique CTDMO Instrument UIDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = sorted(list(set(CTDMO['UID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the QCT Testing documents associated with each individual instrument (the UID):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_dict = get_qct_files(CTDMO, qct_directory)\n",
    "qct_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the calibration csvs stored in asset management which correspond to a particular instrument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dict = load_asset_management(CTDMO, asset_management_directory)\n",
    "csv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the serial numbers for each CTDMO, and use those serial numbers to search for and return all of the relevant vendor documents for a particular instrument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_nums = get_serial_nums(CTDMO, uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dict = get_calibration_files(serial_nums, cal_directory)\n",
    "cal_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Print all of the CTDMO CSV files in order to retrieve all of the relevant files that need to be checked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in sorted(csv_dict.keys()):\n",
    "    files = sorted(csv_dict[uid])\n",
    "    sn = serial_nums[uid]\n",
    "    for f in files:\n",
    "        print('CTDMO-G' + '  ' + '37-' + sn + '  ' + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "With the individual files identified for the CTDMO Vendor documents, QCTs, and CSVs, we next get the full directory path to the files. This is necessary to load them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = {}\n",
    "for uid in sorted(csv_dict.keys()):\n",
    "    paths = []\n",
    "    for file in csv_dict.get(uid):\n",
    "        path = generate_file_path(asset_management_directory, file, ext=['.csv','.ext'])\n",
    "        paths.append(path)\n",
    "    csv_paths.update({uid: paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAL file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save the full directory path to the calibration files\n",
    "cal_paths = {}\n",
    "for uid in sorted(cal_dict.keys()):\n",
    "    paths = []\n",
    "    for file in cal_dict.get(uid):\n",
    "        path = generate_file_path(cal_directory, file, ext=['.zip','.cap', '.txt', '.log'])\n",
    "        paths.append(path)\n",
    "    cal_paths.update({uid: paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QCT file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_paths = {}\n",
    "for uid in sorted(qct_dict.keys()):\n",
    "    paths = []\n",
    "    for file in qct_dict.get(uid):\n",
    "        path = generate_file_path(qct_directory, file)\n",
    "        paths.append(path)\n",
    "    qct_paths.update({uid: paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "# Processing and Parsing the Calibration Coefficients\n",
    "With the associated vendor documents (cal files/vendor pdfs), QCT checkins (qct files), and calibration csvs (csv files), I want to be able to compare the following:\n",
    "* **(1)** That the calibration date matches between the different documents\n",
    "* **(2)** The file name agrees with the CTDMO UID and the calibration date\n",
    "* **(3)** The calibration coefficients all agree between the different reference documents and calibration csvs\n",
    "* **(4)** Identify when a calibration coefficient is incorrect, where to find it, and how to correct it\n",
    "\n",
    "The first step is to define a CTDMO Calibration parsing object. This object contains the relevant attributes and the functions necessary to open, read, and parse the CTDMO calibration coefficients and date, and write the calibration info to a properly-named CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wcmatch import fnmatch\n",
    "from zipfile import ZipFile\n",
    "import textract\n",
    "\n",
    "class CTDMOCalibration():\n",
    "    # Class that stores calibration values for CTDs.\n",
    "\n",
    "    def __init__(self, uid):\n",
    "        self.serial = ''\n",
    "        self.uid = uid\n",
    "        self.ctd_type = uid\n",
    "        self.coefficients = {}\n",
    "        self.date = {}\n",
    "\n",
    "        # Name mapping for the MO-type CTDs (when reading from pdfs)\n",
    "        self.mo_coefficient_name_map = {\n",
    "            'ptcb1': 'CC_ptcb1',\n",
    "            'pa2': 'CC_pa2',\n",
    "            'a3': 'CC_a3',\n",
    "            'pa0': 'CC_pa0',\n",
    "            'wbotc': 'CC_wbotc',\n",
    "            'ptcb0': 'CC_ptcb0',\n",
    "            'g': 'CC_g',\n",
    "            'ptempa1': 'CC_ptempa1',\n",
    "            'ptcb2': 'CC_ptcb2',\n",
    "            'a0': 'CC_a0',\n",
    "            'h': 'CC_h',\n",
    "            'ptca0': 'CC_ptca0',\n",
    "            'a2': 'CC_a2',\n",
    "            'cpcor': 'CC_cpcor',\n",
    "            'pcor':'CC_cpcor',\n",
    "            'i': 'CC_i',\n",
    "            'ptempa0': 'CC_ptempa0',\n",
    "            'prange': 'CC_p_range',\n",
    "            'ctcor': 'CC_ctcor',\n",
    "            'tcor':'CC_ctcor',\n",
    "            'a1': 'CC_a1',\n",
    "            'j': 'CC_j',\n",
    "            'ptempa2': 'CC_ptempa2',\n",
    "            'pa1': 'CC_pa1',\n",
    "            'ptca1': 'CC_ptca1',\n",
    "            'ptca2': 'CC_ptca2',\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def uid(self):\n",
    "        return self._uid\n",
    "\n",
    "    @uid.setter\n",
    "    def uid(self, d):\n",
    "        r = re.compile('.{5}-.{6}-.{5}')\n",
    "        if r.match(d) is not None:\n",
    "            self.serial = d.split('-')[2]\n",
    "            self._uid = d\n",
    "        else:\n",
    "            raise Exception(f\"The instrument uid {d} is not a valid uid. Please check.\")\n",
    "\n",
    "    @property\n",
    "    def ctd_type(self):\n",
    "        return self._ctd_type\n",
    "\n",
    "    @ctd_type.setter\n",
    "    def ctd_type(self, d):\n",
    "        if 'MO' in d:\n",
    "            self._ctd_type = '37'\n",
    "        elif 'BP' in d:\n",
    "            self._ctd_type = '16'\n",
    "        else:\n",
    "            self._ctd_type = ''\n",
    "\n",
    "            \n",
    "    def mo_parse_pdf(self, filepath):\n",
    "        \"\"\"\n",
    "        This function extracts the text from a given pdf file.\n",
    "        Depending on if the text concerns calibration for \n",
    "        temperature/conductivity or pressure, it calls a further\n",
    "        function to parse out the individual calibration coeffs.\n",
    "    \n",
    "        Args:\n",
    "            filepath - the full directory path to the pdf file\n",
    "                which it to be extracted and parsed.\n",
    "        Calls:\n",
    "            mo_parse_p(text, filepath)\n",
    "            mo_parse_ts(text)\n",
    "        Returns:\n",
    "            self - a CTDMO calibration object with calibration\n",
    "                coefficients parsed into the object calibration\n",
    "                dictionary\n",
    "        \"\"\"\n",
    "    \n",
    "        text = textract.process(filepath, encoding='utf-8')\n",
    "        text = text.decode('utf-8')\n",
    "    \n",
    "        if 'PRESSURE CALIBRATION DATA' in text:\n",
    "            self.mo_parse_p(filepath)\n",
    "    \n",
    "        elif 'TEMPERATURE CALIBRATION DATA' or 'CONDUCTIVITY CALIBRATION DATA' in text:\n",
    "            self.mo_parse_ts(text)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    def mo_parse_ts(self, text):\n",
    "        \"\"\"\n",
    "        This function parses text from a pdf and loads the appropriate calibration\n",
    "        coefficients for the temperature and conductivity sensors into the CTDMO \n",
    "        calibration object.\n",
    "    \n",
    "        Args:\n",
    "            text - extracted text from a pdf page\n",
    "        Returns:\n",
    "            self - a CTDMO calibration object with either temperature or conductivity\n",
    "                calibration values filled in the calibration coefficients dictionary\n",
    "        Raises:\n",
    "            Exception - if the serial number in the pdf text does not match the\n",
    "                serial number parsed from the UID\n",
    "        \"\"\"\n",
    "    \n",
    "        keys = self.mo_coefficient_name_map.keys()\n",
    "        for line in text.splitlines():\n",
    "    \n",
    "            if 'CALIBRATION DATE' in line:\n",
    "                *ignore, cal_date = line.split(':')\n",
    "                cal_date = pd.to_datetime(cal_date).strftime('%Y%m%d')\n",
    "                self.date.update({len(self.date): cal_date})\n",
    "        \n",
    "            elif 'SERIAL NUMBER' in line:\n",
    "                *ignore, serial_num = line.split(':')\n",
    "                serial_num = serial_num.strip()\n",
    "                if serial_num != self.serial:\n",
    "                    raise Exception(f'Instrument serial number {serial_num} does not match UID serial num {self.serial}')\n",
    "           \n",
    "            elif '=' in line:\n",
    "                key, *ignore, value = line.split()\n",
    "                name = self.mo_coefficient_name_map.get(key.strip().lower())\n",
    "                if name is not None:\n",
    "                    self.coefficients.update({name: value.strip()})\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "    def mo_parse_p(self,filepath):\n",
    "        \"\"\"\n",
    "        Function to parse the pressure calibration information from a pdf. To parse\n",
    "        the pressure cal info requires re-extracting the text from the pdf file using\n",
    "        tesseract-ocr rather than the basic pdf2text converter.\n",
    "    \n",
    "        Args:\n",
    "            text - extracted text from a pdf page using pdf2text\n",
    "            filepath - full directory path to the pdf file containing the pressure\n",
    "                calibration info. This is the file which will be re-extracted.\n",
    "        Returns\n",
    "            self - a CTDMO calibration object with pressure calibration values filled\n",
    "                in the calibration coefficients dictionary\n",
    "        \"\"\"\n",
    "    \n",
    "        # Now, can reprocess using tesseract-ocr rather than pdftotext\n",
    "        ptext = textract.process(filepath, method='tesseract', encoding='utf-8')\n",
    "        ptext = ptext.replace(b'\\xe2\\x80\\x94',b'-')\n",
    "        ptext = ptext.decode('utf-8')\n",
    "        keys = list(self.mo_coefficient_name_map.keys())\n",
    "        \n",
    "        # Get the calibration date:\n",
    "        for line in ptext.splitlines():\n",
    "            if 'CALIBRATION DATE' in line:\n",
    "                items = line.split()\n",
    "                ind = items.index('DATE:')\n",
    "                cal_date = items[ind+1]\n",
    "                cal_date = pd.to_datetime(cal_date).strftime('%Y%m%d')\n",
    "                self.date.update({len(self.date):cal_date})\n",
    "            \n",
    "            if 'psia S/N' in line:\n",
    "                items = line.split()\n",
    "                ind = items.index('psia')\n",
    "                prange = items[ind-1]\n",
    "                name = self.mo_coefficient_name_map.get('prange')\n",
    "                self.coefficients.update({name: prange})\n",
    "    \n",
    "            # Loop through each line looking for the lines which contain\n",
    "            # calibration coefficients\n",
    "            if '=' in line:\n",
    "                # Tesseract-ocr misreads '0' as O, and 1 as IL\n",
    "                line = line.replace('O','0').replace('IL','1').replace('=','').replace(',.','.').replace(',','.')\n",
    "                line = line.replace('L','1').replace('@','0').replace('l','1').replace('--','-')\n",
    "                if '11' in line and 'PA2' not in line:\n",
    "                    line = line.replace('11','1')\n",
    "                items = line.split()\n",
    "                for n, k in enumerate(items):\n",
    "                    if k.lower() in keys:\n",
    "                        try:\n",
    "                            float(items[n+1])\n",
    "                            name = self.mo_coefficient_name_map.get(k.lower())\n",
    "                            self.coefficients.update({name: items[n+1]})\n",
    "                        except:\n",
    "                            pass\n",
    "        if 'CC_ptcb2' not in list(self.mo_coefficient_name_map.keys()):\n",
    "            self.coefficients.update({'CC_ptcb2': '0.000000e+000'})\n",
    "\n",
    "\n",
    "    def mo_parse_cal(self, filepath):\n",
    "        \"\"\"\n",
    "        Function to parse the .cal file for the CTDMO when a .cal file\n",
    "        is available.\n",
    "        \"\"\"\n",
    "    \n",
    "        if not filepath.endswith('.cal'):\n",
    "            raise Exception(f'Not a .cal filetype.')\n",
    "    \n",
    "        with open(filepath) as file:\n",
    "            data = file.read()\n",
    "        \n",
    "        for line in data.splitlines():\n",
    "            key, value = line.split('=')\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "        \n",
    "            if 'SERIALNO' in key:\n",
    "                sn = value\n",
    "                if self.serial != sn:\n",
    "                    raise Exception(f'File serial number {sn} does not match UID {self.uid}')\n",
    "                \n",
    "            elif 'CALDATE' in key:\n",
    "                cal_date = pd.to_datetime(value).strftime('%Y%m%d')\n",
    "                self.date.update({len(self.date): cal_date})\n",
    "            \n",
    "            elif 'INSTRUMENT_TYPE' in key:\n",
    "                ctd_type = value[-2:]\n",
    "                if self.ctd_type != ctd_type:\n",
    "                    raise Exception(f'CTD type {ctd_type} does not match uid {self.uid}.')\n",
    "                \n",
    "            else:\n",
    "                if key.startswith('T'):\n",
    "                    key = key.replace('T','')\n",
    "                if key.startswith('C') and len(key)==2:\n",
    "                    key = key.replace('C','')\n",
    "                name = self.mo_coefficient_name_map.get(key.lower())\n",
    "                if name is not None:\n",
    "                    self.coefficients.update({name: value})\n",
    "                    \n",
    "        # Now we need to add in the range of the sensor\n",
    "        name = self.mo_coefficient_name_map.get('prange')\n",
    "        self.coefficients.update({name: '1450'})\n",
    "\n",
    "                    \n",
    "    def mo_parse_qct(self, filepath):\n",
    "        \"\"\"\n",
    "        This function reads and parses the QCT file into\n",
    "        the CTDMO calibration object.\n",
    "    \n",
    "        Args:\n",
    "            filepath - full directory path and filename of\n",
    "                the QCT file\n",
    "        Returns:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        with open(filepath,errors='ignore') as file:\n",
    "            data = file.read()\n",
    "\n",
    "        data = data.replace('<',' ').replace('>',' ')\n",
    "        keys = self.mo_coefficient_name_map.keys()\n",
    "\n",
    "        for line in data.splitlines():\n",
    "            items = line.split()\n",
    "    \n",
    "            # If the line is empty, go to next line\n",
    "            if len(items) == 0:\n",
    "                continue\n",
    "    \n",
    "            # Check the serial number from the instrument\n",
    "            elif 'SERIAL NO' in line:\n",
    "                ind = items.index('NO.')\n",
    "                sn = items[ind+1]\n",
    "                if sn != self.serial:\n",
    "                    raise Exception(f'Serial number {sn} in QCT document does not match uid serial number {self.serial}')\n",
    "        \n",
    "            # Check if the line contains the calibration date\n",
    "            elif 'CalDate' in line:\n",
    "                cal_date = pd.to_datetime(items[1]).strftime('%Y%m%d')\n",
    "                self.date.update({len(self.date): cal_date})\n",
    "        \n",
    "            # Get the coefficient names and values\n",
    "            elif items[0].lower() in keys:\n",
    "                name = self.mo_coefficient_name_map[items[0].lower()]\n",
    "                self.coefficients.update({name: items[1]})\n",
    "        \n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    \n",
    "    def write_csv(self, outpath):\n",
    "        \"\"\"\n",
    "        This function writes the correctly named csv file for the ctd to the\n",
    "        specified directory.\n",
    "\n",
    "        Args:\n",
    "            outpath - directory path of where to write the csv file\n",
    "        Raises:\n",
    "            ValueError - raised if the CTD object's coefficient dictionary\n",
    "                has not been populated\n",
    "        Returns:\n",
    "            self.to_csv - a csv of the calibration coefficients which is\n",
    "                written to the specified directory from the outpath.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run a check that the coefficients have actually been loaded\n",
    "        if len(self.coefficients) == 0:\n",
    "            raise ValueError('No calibration coefficients have been loaded.')\n",
    "\n",
    "        # Create a dataframe to write to the csv\n",
    "        data = {'serial': [self.ctd_type + '-' + self.serial]*len(self.coefficients),\n",
    "                'name': list(self.coefficients.keys()),\n",
    "                'value': list(self.coefficients.values()),\n",
    "                'notes': ['']*len(self.coefficients)\n",
    "                }\n",
    "        df = pd.DataFrame().from_dict(data)\n",
    "\n",
    "        # Generate the csv name\n",
    "        cal_date = max(self.date.values())\n",
    "        csv_name = self.uid + '__' + cal_date + '.csv'\n",
    "\n",
    "        # Write the dataframe to a csv file\n",
    "        # check = input(f\"Write {csv_name} to {outpath}? [y/n]: \")\n",
    "        check = 'y'\n",
    "        if check.lower().strip() == 'y':\n",
    "            df.to_csv(outpath+'/'+csv_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Below, I plan on going through each of the CTDMO UIDs, and parse the data into csvs. For source files which may contain multiple calibrations or calibration sources, I plan on extracting each of the calibrations to a temporary folder using the following structure:\n",
    "\n",
    "    <local working directory>/<temp>/<source>/data/<calibration file>\n",
    "    \n",
    "The separate calibrations will be saved using the standard UFrame naming convention with the following directory structure:\n",
    "\n",
    "    <local working directory>/<temp>/<source>/<calibration csv>\n",
    "    \n",
    "The csvs themselves will also be copied to the temporary folder. This allows for the program to be looking into the same temp directory for every CTDMO check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = sorted(uids)[163]\n",
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = '/'.join((os.getcwd(),'temp'))\n",
    "if os.path.exists(temp_directory):\n",
    "    shutil.rmtree(temp_directory)\n",
    "    ensure_dir(temp_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=======================================================================================================================**\n",
    "Copy the existing CTDMO asset management csvs to the local temp directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in csv_paths[uid]:\n",
    "    savedir = '/'.join((temp_directory,'csv'))\n",
    "    ensure_dir(savedir)\n",
    "    savepath = '/'.join((savedir, filepath.split('/')[-1]))\n",
    "    shutil.copyfile(filepath, savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================\n",
    "### Parse and process the vendor documents\n",
    "The next step is to read and parse the vendor documents. This is a more difficult challenge, since for CTDMOs the vendor documents are retained mostly as pdf files. While the pdf files are parseable, there is an added complication in that the forms have changed over time, with sometimes the T/S/P calibration pdfs combined into a single file, whereas other times they are separated into individual files. Furthermore, the files are often zipped into a single folder. So, I have the following possible vendor documents:\n",
    "* **(1)** A .cal file - this is the easiest to read and parse, in a similar format to the CTDBP .cal files\n",
    "* **(2)** A combinded pdf - this is the most difficult format. Need to separate out the different pages which each separately contain either the temperature calibration info, the conductivity calibration info, or the pressure calibration info.\n",
    "* **(3)** Separate pdfs - this is a simpler pdf reading schematic, where I know a priori which particular \"page\" will contain relevant calibration info. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of different pdf readers that I can use:\n",
    "1. PyPDF2\n",
    "2. PDFMiner\n",
    "3. Textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDF2 does not work to extract text from the CTDMO combined pdf file document. Neither does the straightforward PDFMiner application. We will have to use OCR and textract to parse the pdf forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When parsing the pdf file, it appears that the built-in method of pdf2text does the best job at parsing the forms, particularly the temperature and conductivity coefficients. The pressure calibration coefficients are not as well parsed, due to the positioning of the image.\n",
    "\n",
    "This means that I'm going to split and use two different methods for getting the calibration coefficients depending on what the calibration is for, i.e. T/S/P. For T and S, I'll use the built-in method for extracting text. For the pressure, I'll use the tesseract OCR approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================\n",
    "### Preprocessing the Vendor Files\n",
    "In order to automate the parsing of the CTDMO calibration coefficients from pdf files into csv files that can be read by Python requires a bit of preprocessing. In particular, the following steps are taken to make parsing the files:\n",
    "* **(1)** Copy or extract the vendor calibration files from the Vault location to a local temp directory\n",
    "* **(2)** Iterate over the available pdfs and split multipage pdfs into single page pdfs and append _page_ to the file\n",
    "* **(3)** Once the pdfs have been split, they are ready to be parsed by the CTDMO object parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, write a function to copy over the file\n",
    "cal_paths[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the vendor pdf files to a local temporary directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in cal_paths[uid]:\n",
    "    folder, *ignore = filepath.split('/')[-1].split('.')\n",
    "    savedir = '/'.join((temp_directory,'data',folder))\n",
    "    ensure_dir(savedir)\n",
    "    \n",
    "    if filepath.endswith('.zip'):\n",
    "        with ZipFile(filepath,'r') as zfile:\n",
    "            for file in zfile.namelist():\n",
    "                zfile.extract(file, path=savedir)\n",
    "    else:\n",
    "        shutil.copy(filepath, savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('/'.join((temp_directory,'data',folder))):\n",
    "    if os.path.isdir('/'.join((temp_directory,'data',folder,file))):\n",
    "        for subfile in os.listdir('/'.join((temp_directory,'data',folder,file))):\n",
    "            src = '/'.join((temp_directory,'data',folder,file,subfile))\n",
    "            dst = '/'.join((temp_directory,'data',folder,subfile))\n",
    "            shutil.move(src,dst)\n",
    "        shutil.rmtree('/'.join((temp_directory,'data',folder,file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir('/'.join((os.getcwd(),'temp','data')))\n",
    "rmfile = None\n",
    "for folder in folders:\n",
    "    filepath = '/'.join((os.getcwd(),'temp','data',folder))\n",
    "    \n",
    "    if any([file for file in os.listdir(filepath) if file.endswith('.cal')]):\n",
    "        pass\n",
    "    else:\n",
    "        files = [file for file in os.listdir(filepath) if 'SERVICE REPORT' not in file]\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            for file in files:\n",
    "                trip = False\n",
    "                inputpath = '/'.join((filepath,file))\n",
    "                inputpdf = PyPDF2.PdfFileReader(inputpath, 'rb')\n",
    "\n",
    "                for i in range(inputpdf.numPages):\n",
    "                    output = PyPDF2.PdfFileWriter()\n",
    "                    output.addPage(inputpdf.getPage(i))\n",
    "                    filename = '_'.join((inputpath.split('.')[0], 'page', str(i)))\n",
    "                    with open(filename+'.pdf', \"wb\") as outputStream:\n",
    "                        output.write(outputStream)\n",
    "        except:\n",
    "            rmfile = filepath\n",
    "            print(f'Cannot reformat {filepath}')\n",
    "            \n",
    "if rmfile is not None:\n",
    "    shutil.rmtree(rmfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(temp_directory+'/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to iterate over the vendor calibration files and extract the calibration coefficients from the files. This is done by starting an instance of the CTDMO calibration object, check if any of the calibration data is stored as a .cal file, if no .cal file loop over the other files looking for _page_ files which indicates that the pdf file has been prepped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.abspath('/'.join((os.getcwd(),'temp','data')))\n",
    "for folder in os.listdir(datadir):\n",
    "    # Okay, now start generating calibration csvs\n",
    "    ctdmo = CTDMOCalibration(uid)\n",
    "    files = [file for file in os.listdir('/'.join((datadir,folder)))]\n",
    "    if any([file for file in files if file.endswith('.cal')]):\n",
    "        for file in files:\n",
    "            if file.endswith('.cal'):\n",
    "                ctdmo.mo_parse_cal('/'.join((datadir,folder,file)))\n",
    "    else:\n",
    "        for file in files:\n",
    "            if '_page_' in file:\n",
    "                try:\n",
    "                    ctdmo.mo_parse_pdf('/'.join((datadir,folder,file)))\n",
    "                except:\n",
    "                    print(f'Parsing failed for {file}')\n",
    "                    \n",
    "    savedir = '/'.join((os.getcwd(),'temp','cal'))\n",
    "    ensure_dir(savedir)\n",
    "    try:\n",
    "        ctdmo.write_csv(savedir)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the calibration object properly loaded all of the calibration coefficients, serial number, calibration date, etc., and wrote the appropriate csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(temp_directory+'/cal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=======================================================================================================================**\n",
    "Next, we need to parse the QCT files and check that they have been successfully saved to a csv file. There should be 24 coefficients. Similarly, check the instrument serial number, the calibration date (may be more than one b/c separate calibration dates for T, S, and P sensors), and the type (for CTDMOs should be 37)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in qct_paths[uid]:\n",
    "    savedir = '/'.join((temp_directory,'qct'))\n",
    "    ensure_dir(savedir)\n",
    "    if filepath is not None:\n",
    "        try:\n",
    "            ctdmo = CTDMOCalibration(uid)\n",
    "            ctdmo.mo_parse_qct(filepath)\n",
    "            ctdmo.write_csv(savedir)\n",
    "        except:\n",
    "            print(f'Failed to parse {filepath}')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_paths[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/'.join((temp_directory,'qct')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "### Compare results\n",
    "Now, with QCT files parsed into csvs which follow the UFrame format, I can load both the QCT and the calibratoin csvs into pandas dataframes, which will allow element by element comparison in relatively few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_date(x):\n",
    "    x = str(x)\n",
    "    ind1 = x.index('__')\n",
    "    ind2 = x.index('.')\n",
    "    return x[ind1+2:ind2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the calibration csvs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to compare dataframe\n",
    "csv_files = pd.DataFrame(sorted(os.listdir('temp/csv')),columns=['csv'])\n",
    "csv_files['cal date'] = csv_files['csv'].apply(lambda x: get_file_date(x))\n",
    "csv_files.set_index('cal date',inplace=True)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the QCT csvs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to compare dataframe\n",
    "qct_files = pd.DataFrame(sorted(os.listdir('temp/qct')),columns=['qct'])\n",
    "qct_files['cal date'] = qct_files['qct'].apply(lambda x: get_file_date(x))\n",
    "qct_files.set_index('cal date',inplace=True)\n",
    "qct_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the calibration csvs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_files = pd.DataFrame(sorted(os.listdir('temp/cal')),columns=['cal'])\n",
    "cal_files['cal date'] = cal_files['cal'].apply(lambda x: get_file_date(x))\n",
    "cal_files.set_index('cal date',inplace=True)\n",
    "cal_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the dataframes into one in order to know which csv files to compare and check calibration dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = csv_files.join(qct_files,how='outer').join(cal_files,how='outer').fillna(value='-999')\n",
    "df_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the filename is wrong, the calibration coefficient checker will not manage to compare the results. Consequently, we'll make a local copy of the wrong file to a new file with the correct name, and then run the calibration coefficient checker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = str(20151217)\n",
    "d2 = str(20150625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f'temp/csv/{uid}__{d1}.csv'\n",
    "dst = f'temp/csv/{uid}__{d2}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('temp/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the data so that all files are uniformly named:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = pd.DataFrame(sorted(os.listdir('temp/csv')),columns=['csv'])\n",
    "csv_files['cal date'] = csv_files['csv'].apply(lambda x: get_file_date(x))\n",
    "csv_files.set_index('cal date',inplace=True)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = csv_files.join(qct_files,how='outer').join(cal_files,how='outer').fillna(value='-999')\n",
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caldates = df_files.index\n",
    "for i in caldates:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cpath in sorted(cal_paths[uid]):\n",
    "    print(cpath.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for qpath in qct_paths[uid]:\n",
    "    if qpath is not None:\n",
    "        print(qpath.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With uniformly named csv files, we can now directly compare different calibration coefficient sources for the CTDMO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table tells us that, for the csv CGINS-CTDMOG-11596__20150608.csv, I am missing a QCT document and vendor doc which could verify the calibration coefficients. Next, for the files I can compare, I want to go through and check each calibration coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Okay, I want to check the following in the comparison between the CSV files contained in Asset Management, the QCT checkins, and the vendor docs:\n",
    "1. Do the calibration coefficients match exactly?\n",
    "2. Do the calibration coefficients match to within 0.001%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exact_coeffs(coeffs_dict):\n",
    "    \n",
    "    # Part 1: coeff by coeff comparison between each source of coefficients\n",
    "    keys = list(coeffs_dict.keys())\n",
    "    comparison = {}\n",
    "    for i in range(len(keys)):\n",
    "        names = (keys[i], keys[i - (len(keys)-1)])\n",
    "        check = len(coeffs_dict.get(keys[i])['value']) == len(coeffs_dict.get(keys[i - (len(keys)-1)])['value'])\n",
    "        if check:\n",
    "            compare = np.equal(coeffs_dict.get(keys[i])['value'], coeffs_dict.get(keys[i - (len(keys)-1)])['value'])\n",
    "            comparison.update({names:compare})\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # Part 2: now do a logical_and comparison between the results from part 1\n",
    "    keys = list(comparison.keys())\n",
    "    i = 0\n",
    "    mask = comparison.get(keys[i])\n",
    "    while i < len(keys)-1:\n",
    "        i = i + 1\n",
    "        mask = np.logical_and(mask, comparison.get(keys[i]))\n",
    "        print(i)\n",
    "       \n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relative_coeffs(coeffs_dict):\n",
    "    \n",
    "    # Part 1: coeff by coeff comparison between each source of coefficients\n",
    "    keys = list(coeffs_dict.keys())\n",
    "    comparison = {}\n",
    "    for i in range(len(keys)):\n",
    "        names = (keys[i], keys[i - (len(keys)-1)])\n",
    "        check = len(coeffs_dict.get(keys[i])['value']) == len(coeffs_dict.get(keys[i - (len(keys)-1)])['value'])\n",
    "        if check:\n",
    "            compare = np.isclose(coeffs_dict.get(keys[i])['value'], coeffs_dict.get(keys[i - (len(keys)-1)])['value'], rtol=1e-5)\n",
    "            comparison.update({names:compare})\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # Part 2: now do a logical_and comparison between the results from part 1\n",
    "    keys = list(comparison.keys())\n",
    "    i = 0\n",
    "    mask = comparison.get(keys[i])\n",
    "    while i < len(keys)-1:\n",
    "        i = i + 1\n",
    "        mask = np.logical_and(mask, comparison.get(keys[i]))\n",
    "        print(i)\n",
    "       \n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = {}\n",
    "for cal_date in df_files.index:\n",
    "    # Part 1, load all of the csv files\n",
    "    coeffs_dict = {}\n",
    "    for source,fname in df_files.loc[cal_date].items():\n",
    "        if fname != '-999':\n",
    "            load_directory = '/'.join((os.getcwd(),'temp',source,fname))\n",
    "            df_coeffs = pd.read_csv(load_directory)\n",
    "            for i in list(set(df_coeffs['serial'])):\n",
    "                print(source + '-' + fname + ': ' + str(i))\n",
    "            df_coeffs.set_index(keys='name',inplace=True)\n",
    "            df_coeffs.sort_index(inplace=True)\n",
    "            coeffs_dict.update({source:df_coeffs})\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Part 2, now check the calibration coefficients\n",
    "    mask = check_exact_coeffs(coeffs_dict)\n",
    "    \n",
    "    # Part 3: get the calibration coefficients are wrong\n",
    "    # and show them\n",
    "    fname = df_files.loc[cal_date]['csv']\n",
    "    if fname == '-999':\n",
    "        incorrect = 'No csv file.'\n",
    "    else:\n",
    "        incorrect = coeffs_dict['csv'][mask == False]\n",
    "    exact_match.update({fname:incorrect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_match = {}\n",
    "for cal_date in df_files.index:\n",
    "    # Part 1, load all of the csv files\n",
    "    coeffs_dict = {}\n",
    "    for source,fname in df_files.loc[cal_date].items():\n",
    "        if fname != '-999':\n",
    "            load_directory = '/'.join((os.getcwd(),'temp',source,fname))\n",
    "            df_coeffs = pd.read_csv(load_directory)\n",
    "            for i in list(set(df_coeffs['serial'])):\n",
    "                print(source + '-' + fname + ': ' + str(i))\n",
    "            df_coeffs.set_index(keys='name',inplace=True)\n",
    "            df_coeffs.sort_index(inplace=True)\n",
    "            coeffs_dict.update({source:df_coeffs})\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Part 2, now check the calibration coefficients\n",
    "    mask = check_relative_coeffs(coeffs_dict)\n",
    "    \n",
    "    # Part 3: get the calibration coefficients are wrong\n",
    "    # and show them\n",
    "    fname = df_files.loc[cal_date]['csv']\n",
    "    if fname == '-999':\n",
    "        incorrect = 'No csv file.'\n",
    "    else:\n",
    "        incorrect = coeffs_dict['csv'][mask == False]\n",
    "    relative_match.update({fname:incorrect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(exact_match.keys()):\n",
    "    if key != '-999':\n",
    "        print(', '.join((ind for ind in exact_match[key].index.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in sorted(relative_match.keys()):\n",
    "    if key != '-999':\n",
    "        print(', '.join((ind for ind in relative_match[key].index.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Now we need to check that the calibration coefficients for each CTDMO csv have the same number of significant digits as are reported on the vendor PDFs. For the CTDMO, the vendor reports to six significant figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = uids[0]\n",
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = pd.read_csv(csv_paths[uid][0])\n",
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in CSV['value']:\n",
    "    print(\"{:.6e}\".format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:.2e}\".format(0.00253))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_precision(x,p):\n",
    "    \"\"\"\n",
    "    Returns a string representation of x formatted with a precision of p,\n",
    "    following the toPrecision method from javascript. This implementation\n",
    "    is based on example code from www.randlet.com.\n",
    "    \n",
    "    Args:\n",
    "        x - number to format to a specified precision\n",
    "        p - the specified precision for the number x\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # First check if x is a string\n",
    "    if type(x) is not float:\n",
    "        x = float(x)\n",
    "        \n",
    "    # Next, check if p is an int and if not, convert to int\n",
    "    if type(p) is not int:\n",
    "        p = int(p)\n",
    "    \n",
    "        \n",
    "    if x == 0.:\n",
    "        return \"0.\" + \"0\"*(p-1)\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    if x < 0:\n",
    "        out.append(\"-\")\n",
    "        x = -x\n",
    "        \n",
    "    e = int(math.log10(x))\n",
    "    tens = math.pow(10, e - p + 1)\n",
    "    n = math.floor(x / tens)\n",
    "    \n",
    "    if n < math.pow(10, p - 1):\n",
    "        e = e - 1\n",
    "        tens = math.pow(10, e - p + 1)\n",
    "        n = math.floor(x / tens)\n",
    "        \n",
    "    if abs((n + 1.) * tens - x) <= abs(n * tens - x):\n",
    "        n = n + 1\n",
    "        \n",
    "    if n >= math.pow(10, p):\n",
    "        n = n / 10.\n",
    "        e = e + 1\n",
    "        \n",
    "    m = \"%.*g\" % (p, n)\n",
    "    \n",
    "    if e < -2 or e >= p:\n",
    "        out.append(m[0])\n",
    "        if p > 1:\n",
    "            out.append(\".\")\n",
    "            out.extend(m[1:p])\n",
    "        out.append('e')\n",
    "        if e > 0:\n",
    "            out.append(\"+\")\n",
    "        out.append(str(e))\n",
    "    elif e == (p - 1):\n",
    "        out.append(m)\n",
    "    elif e >= 0:\n",
    "        out.append(m[:e+1])\n",
    "        if (e + 1) < len(m):\n",
    "            out.append(\".\")\n",
    "            out.extend(m[e+1:])\n",
    "    else:\n",
    "        out.append(\"0.\")\n",
    "        out.extend([\"0\"]*-(e+1))\n",
    "        out.append(m)\n",
    "        \n",
    "    return \"\".join(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
